{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(' ')]\n",
    "    print(\"values\",values)\n",
    "    return LabeledPoint(values[0], values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"pandas.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from txt file pandas.txt MapPartitionsRDD[8] at textFile at <unknown>:0\n"
     ]
    }
   ],
   "source": [
    "print(\"data from txt file\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedData = data.map(parsePoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsedDate PythonRDD[9] at RDD at PythonRDD.scala:48\n"
     ]
    }
   ],
   "source": [
    "print(\"parsedDate\",parsedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.17338458929278083\n"
     ]
    }
   ],
   "source": [
    "model = SVMWithSGD.train(parsedData, iterations=100)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "# model.save(sc, \"pythonSVMWithSGDModel\")\n",
    "# sameModel = SVMModel.load(sc, \"pythonSVMWithSGDModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.06261835626814796\n"
     ]
    }
   ],
   "source": [
    "data_test = sc.textFile(\"pandas_test.txt\")\n",
    "parsedData_test = data_test.map(parsePoint)\n",
    "labelsAndPreds_test = parsedData_test.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr_test = labelsAndPreds_test.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData_test.count())\n",
    "print(\"Testing Error = \" + str(trainErr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP = 401\n",
      "FN = 95\n",
      "TN = 7420\n",
      "TP = 5\n",
      "all numbers = 7921.0\n"
     ]
    }
   ],
   "source": [
    "TP = labelsAndPreds_test.filter(lambda lp: lp[0] == 1 and lp[1]==1).count() \n",
    "FP = labelsAndPreds_test.filter(lambda lp: lp[0] == 0 and lp[1]==1).count() \n",
    "FN = labelsAndPreds_test.filter(lambda lp: lp[0] == 1 and lp[1]==0).count() \n",
    "TN = labelsAndPreds_test.filter(lambda lp: lp[0] == 0 and lp[1]==0).count() \n",
    "allNum = float(parsedData_test.count())\n",
    "\n",
    "print(\"FP = \"+str(FP))\n",
    "print(\"FN = \"+str(FN))\n",
    "print(\"TN = \"+str(TN))\n",
    "print(\"TP = \"+str(TP))\n",
    "print(\"all numbers = \"+str(allNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "# from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "# from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# # Several of the methods available in scala are currently missing from pyspark\n",
    "# # Load training data in LIBSVM format\n",
    "# # data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_binary_classification_data.txt\")\n",
    "\n",
    "# # Split data into training (60%) and test (40%)\n",
    "# # training, test = data.randomSplit([0.6, 0.4], seed=11)\n",
    "# # training.cache()\n",
    "\n",
    "# # Run training algorithm to build the model\n",
    "# # model = LogisticRegressionWithLBFGS.train(training)\n",
    "\n",
    "# # Compute raw scores on the test set\n",
    "# predictionAndLabels = parsedData.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "# # Instantiate metrics object\n",
    "# metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "\n",
    "# # Area under precision-recall curve\n",
    "# print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    "\n",
    "# # Area under ROC curve\n",
    "# print(\"Area under ROC = %s\" % metrics.areaUnderROC)\n",
    "# Statistics by class\n",
    "# labels = data.map(lambda lp: lp.label).distinct().collect()\n",
    "# for label in sorted(labels):\n",
    "#     print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "#     print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "#     print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "\n",
    "# # Weighted stats\n",
    "# print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "# print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "# print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "# print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "# print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
